#  Dharma-NÄ«ti: The Righteous Strategy
### âš–ï¸ An Explainable Strategy for the Iterated Prisonerâ€™s Dilemma

---

## ğŸ“œ Overview
**Dharma-NÄ«ti** is a rule-based, fully explainable strategy for the **Iterated Prisonerâ€™s Dilemma (IPD)**.  
It is designed to maximize **long-term payoff** by balancing **cooperation, proportional retaliation, noise tolerance, and conditional forgiveness**.

Instead of using black-box learning or reinforcement learning, the strategy leverages **ML-informed behavioral insights** to guide transparent decision rules.

> *"Strength without wisdom leads to ruin, and wisdom without strength invites exploitation."*

---

## âš”ï¸ Team: KODE KILLERS

**Members:**
- **Lavneesh** (Team Leader)
- **Deepanshu**
- **Malika**
- **Jatin**

---

## ğŸ’¡ Core Idea
In repeated interactions, blind greed and blind forgiveness both fail.  
**Dharma-NÄ«ti** follows the principle of *long-term rationality*:

- ğŸ¤ **Start with Cooperation** to establish trust.
- âš”ï¸ **Retaliate Proportionally** against betrayal.
- ğŸ›¡ï¸ **Tolerate Noise** (accidental defections).
- ğŸŒ± **Forgive** only after sustained behavioral reform.
- ğŸ›‘ **Avoid Deadlocks** (permanent mutual defection loops).

This mirrors real-world strategic interactions where **stability** matters more than short-term gains.

---

## âœ¨ Strategy Characteristics

- **ğŸ” Explainable & Deterministic**  
  Every decision is driven by clear rulesâ€”no hidden learning or randomness.

- **ğŸ¤– ML-Informed, Not ML-Controlled**  
  Machine learning is used *offline* to analyze successful IPD strategies and derive thresholds (e.g., cooperation and betrayal rates). Final gameplay decisions remain rule-based.

- **ğŸ›¡ï¸ Robust to Noise**  
  Single or rare defections are treated as noise, preventing overreaction.

- **ğŸ›¡ï¸ Resistant to Exploitation**  
  Persistent betrayal triggers escalating but finite retaliation.

- **ğŸŒ± Forgiving, Not Forgetful**  
  Trust is rebuilt only after sustained cooperative behavior.

---

## ğŸ“Š Behavioral Features used in `feature_engineering.py`
The strategy computes interpretable features aligned with standard IPD datasets:

- **ğŸ”¥ Provocability**: The probability of defecting when the opponent cooperates (Unprovoked aggression).
- **âš”ï¸ Retaliation Rate**: The probability of defecting immediately after the opponent defects.
- **ğŸŒ± Forgiveness Rate**: The probability of returning to cooperation after a defecting state.
- **ğŸ¤ Cooperation Rate**: The overall frequency of cooperative moves.
- **ğŸ First Move C**: The probability of cooperating on the very first move.

These features guide decision thresholds in an explainable manner.

---

## ğŸ§  Decision Logic (High Level) in `Krishna.py`

1.  **Trust**: Cooperate on the first move.
2.  **Justice**: Continue any active proportional retaliation.
3.  **Mercy**: Forgive after sustained reform.
4.  **Defense**: Respond to defection based on severity and history.
5.  **Reciprocity**: Reward cooperation and encourage stability.

---



## ğŸ’» Implementation Details
- **Language**: Python ğŸ
- **Dependencies**: Standard Library + Pandas/NumPy for analysis.
- **Core Class**: `DharmaNitiStrategy`
- **Key Methods**:
  - `decide_move()` â€“ determines next action.
  - `update_history()` â€“ updates internal state.

---

## ğŸ† Evaluation Goals
The strategy is designed to excel in:
- Long tournaments (100â€“200 rounds).
- Matches against diverse opponents (Friendly, Hostile, Random).
- High-noise environments.

**Key Metrics:**
- Average payoff per match.
- Stability of cooperation.
- Resistance to exploitation.

---

## License
This project is intended for **academic, educational, and competitive use**.

---

## Authors
Developed as part of **Turingâ€™s Playground / Weekend of Code (WOC)**  
by a team exploring explainable and ethical decision-making in strategic AI.
